## Feature: Document-to-Quiz Generation (PDF/DOCX → Quiz)

### Context
Build a flow where a user uploads a PDF or Word document. The system extracts the text, analyzes content with AI, and returns a generated quiz. Target stack: Next.js 14 (App Router, RSC-first), TypeScript, TailwindCSS, Supabase (auth/storage), and a vetted LLM provider via server-only APIs. Emphasize secure upload handling, robust parsing, deterministic quiz schema, and clear loading/error states.

### Goals & Inputs/Outputs
- **User input**: One file (PDF or DOCX). Optional parameters: number of questions, question types, difficulty, topic focus, and language.
- **Output**: Quiz object containing metadata, sections, questions (MCQ/True-False/Short-answer), answers, explanations, and difficulty per question. Rendered quiz UI with ability to review.
- **Constraints**: Max file size (e.g., 20MB), supported mime types `application/pdf`, `application/vnd.openxmlformats-officedocument.wordprocessingml.document`. Server-only processing. No PII retention. Compliant logging.

### Security & Compliance
- Validate mime type and extension; reject unsupported types; enforce size limits; strip EXIF/embedded data where applicable.
- Store raw uploads in Supabase Storage private bucket or transient disk (prefer transient if not re-used). Delete temporary files after processing.
- Sanitize extracted text (no HTML injection), escape when rendering, avoid client exposure of raw document unless required.
- Rate-limit by user/session/IP; CSRF protection for POST; authenticated uploads if product requires.
- Secrets in environment variables; never in client; use server actions/API routes only.
- Content safety filter on LLM prompts/outputs. Log prompts minimally with redaction.

### UX Flow (High-Level)
1. User visits `Upload` page and selects a PDF/DOCX. Sets quiz params (question count, types, difficulty).
2. Client posts to server endpoint (server action or route handler) with the file and params.
3. Server extracts text: PDF → text; DOCX → text.
4. Clean and chunk text if long; optionally summarize sections to keep prompt within token limits.
5. AI generates a normalized quiz schema.
6. Persist quiz (optional), then render quiz results page with loading and error states.

### Files and Functions to Add / Modify
- `app/(quiz)/upload/page.tsx`
  - Server component that renders the upload form, SEO metadata, and passes any server config (max size).
- `app/(quiz)/upload/components/upload-form.tsx`
  - Client component for file select + params (question count/types/difficulty), progress, and submit. Guards invalid input.
- `app/api/ingest/route.ts`
  - POST route handler for multipart uploads. Validates, streams to temp, dispatches extraction and quiz generation, returns quiz JSON or error.
- `app/(quiz)/results/[id]/page.tsx` (optional if persisting)
  - Server component to fetch and render a previously generated quiz.
- `components/quiz/quiz-view.tsx`
  - Server component to render quiz schema (supports MCQ/TF/Short-answer). Includes show-answers toggle and explanations.
- `components/quiz/quiz-loading.tsx` and `components/quiz/quiz-error.tsx`
  - UI for loading states and error fallback.
- `lib/text-extract.ts`
  - `extractTextFromPdf(arrayBuffer)` and `extractTextFromDocx(arrayBuffer)` using vetted libraries. Normalization utilities: whitespace collapse, hyphenation fixes.
- `lib/quiz/generate.ts`
  - `generateQuizFromText(text, params)` orchestrates chunking, prompt construction, LLM call, schema validation, retries, and post-processing.
- `lib/quiz/schema.ts`
  - Zod schema for quiz types; parsing and validation logic for AI output.
- `lib/chunking.ts`
  - Text chunking by semantic boundaries; token estimation utility.
- `lib/logger.ts`
  - Server-only logger with redaction. Error and audit logs.
- `lib/rate-limit.ts`
  - IP/user-based rate limiting (e.g., sliding window using Supabase or in-memory with fallback for serverless).
- `types/quiz.ts`
  - Export TypeScript interfaces that mirror `lib/quiz/schema.ts` (generated types from Zod).
- `env.mjs` and `.env.example`
  - Typed env loader for LLM API key and config. Never expose to client.
- `next.config.ts`
  - Ensure `experimental.serverActions` if using server actions; configure body size limit for route handler; headers for security.
- `app/layout.tsx`
  - Add `<link rel="preconnect">` for LLM endpoint if needed; set metadata.
- `app/globals.css`
  - Minor styles for forms and quiz readability.

### Data Model (if persisting quizzes)
- `quiz`: id (uuid), user_id (nullable), created_at, source_filename, num_questions, params (jsonb), quiz_json (jsonb), content_hash.
- Store file only if needed for audit; otherwise store a hash and delete file.

### API/Server Actions
- `POST /api/ingest`
  - Form-data fields: `file`, `numQuestions`, `questionTypes[]`, `difficulty`, `language`.
  - Validations: mime, size, required fields, limits (e.g., `numQuestions ≤ 50`).
  - Flow: extract → clean → chunk → generate → validate → persist (optional) → return quiz.
  - Errors: `400` validation, `413` payload too large, `415` unsupported, `429` rate limit, `500` extraction/generation failures.

### Text Extraction Strategy
1. Detect mime from `Content-Type` and on-read magic bytes.
2. PDF: Use a secure, maintained parser (no JavaScript eval). Extract text per page; preserve headings; ignore images by default.
3. DOCX: Use OOXML parser to extract paragraphs/lists/headings; skip embedded objects.
4. Normalize: decode, remove control characters, fix hyphenation, collapse whitespace, retain basic section markers.

### Chunking & Summarization
- Estimate token length; target chunk size (e.g., 1.5k-2k tokens) with 10-15% overlap.
- Boundary-aware splitting: by headings, paragraphs, page breaks.
- For very large docs: summarize chunks first, then synthesize into a final topic map used for question generation.

### Quiz Generation Algorithm (LLM-Orchestrated)
1. Inputs: normalized text, user params.
2. Build a deterministic system prompt describing exact JSON schema to output and quality constraints (curriculum-style coverage, Bloom levels).
3. Provide document-derived key concepts (from chunk summaries) and require balanced coverage.
4. Ask model to produce:
   - Question set with types: MCQ (1 correct + n distractors), TF, Short-answer.
   - Per-question: difficulty, answer, explanation, source span reference.
5. Parse and validate with Zod; on failure, repair prompt or retry with reduced chunk size.
6. De-duplicate and shuffle; ensure answer/explanations are non-empty and grounded.

### Rendering & UX
- Show quiz title (from doc or fallback) and metadata.
- Render per-question components with accessibility (labels, fieldsets), keyboard-friendly, mobile-first.
- Include loading skeletons while processing; error boundary with actionable messages.
- Provide export options (JSON download) and print-friendly view.

### Observability & Errors
- Structured logs for: upload accepted, extraction started/finished, tokens used, generation status, validation errors.
- Metrics: success rate, average latency, tokens/doc length, question validity.
- User-facing error codes mapped to friendly text.

### Rate Limiting & Quotas
- Per-IP and per-user quotas. Block abusive patterns.
- Backoff on provider `429` with retry-after.

### Performance
- Stream parsing and incremental chunk processing where possible.
- Avoid sending entire doc when not needed; favor summaries for context.
- Cache content hash to reuse previous quiz if same doc uploaded.

### Accessibility & SEO
- Semantic HTML in form and quiz components; aria attributes; visible focus states.
- Metadata in `page.tsx` for upload/results pages. Avoid indexing results if private (`robots` noindex when user-specific).

### Libraries (Evaluate and pick vetted options)
- PDF: `pdf-parse` (Node); avoid unmaintained libs.
- DOCX: `docx` or `y-docx` parsing alternatives; consider `mammoth` for docx → HTML then text.
- Validation: `zod`.
- Rate limit: `@upstash/ratelimit` with Redis or Supabase PG functions.
- Logging: `pino` or lightweight structured logger.
- LLM: OpenAI-compatible SDK via server-only module.

### Phases (optional)
- Phase 1: Data layer and server endpoints
  - Add types, schemas, `lib/text-extract.ts`, `lib/quiz/generate.ts`, `app/api/ingest/route.ts`, env wiring, rate limit, logging.
- Phase 2A: Upload UI
  - `app/(quiz)/upload/page.tsx`, `app/(quiz)/upload/components/upload-form.tsx`, loading/error components.
- Phase 2B: Quiz rendering
  - `components/quiz/quiz-view.tsx` and supporting UI.
- Phase 3 (Optional): Persistence and results page
  - Supabase schema, save/retrieve quizzes, `app/(quiz)/results/[id]/page.tsx`.

### Open Questions (to confirm)
1. Should quizzes be persisted per user in Supabase, or just returned inline?
2. Preferred LLM/provider and any cost/token constraints?
3. Default question count, supported types, and grading mode?
4. Do we need multi-language quiz generation and UI localization?.
5. Maximum document size and timeouts acceptable for users?


